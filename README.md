**The Objective Revision Evaluation Service (ORES)** is a web service running in Wikimedia Labs that provides machine learning as a service for Wikimedia Projects. (<https://ores.wmflabs.org/>). You can read more [here](http://socio-technologist.blogspot.co.il/2015/10/ores-hacking-social-structures-by.html>).

The damage model was trained on human judgement to predict damaging edits. Remember that not all damaging edits are bad-faith.(<https://meta.wikimedia.org/wiki/ORES/damaging>) 

We explored the bias that ORES' damage detection models have against anonymous editors in Wikipedia. We did a statistical analysis to show that the bias is extreme and then changed our modeling strategy to minimize the bias re-measured the effects.

Thanks Aaron for the supervision!